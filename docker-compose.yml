version: '3.8'

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    environment:
      - CLUSTER_NAME=test-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    ports:
      - "9870:9870"   # UI
      - "9000:9000"   # Namenode
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    networks:
      - hadoop-net

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    environment:
      - CLUSTER_NAME=test-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
    ports:
      - "9864:9864"   # UI
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    networks:
      - hadoop-net
    depends_on:
      - namenode

  mongodb:
    image: mongo:6.0
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - hadoop-net
  
  pyspark:
    image: jupyter/pyspark-notebook:spark-3.4.1
    container_name: pyspark
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
    environment:
      - PYSPARK_SUBMIT_ARGS=--packages org.mongodb.spark:mongo-spark-connector_2.12:10.1.1 pyspark-shell
    networks:
      - hadoop-net
    depends_on:
      - namenode
      - datanode
      - mongodb

  streamlit-app:
    build: .
    container_name: streamlit-app
    ports:
      - "8501:8501"
    networks:
      - hadoop-net
    depends_on:
      - pyspark
    environment:
      - JAVA_HOME=/usr/lib/jvm/java-17-openjdk-arm64
      - PATH=/usr/lib/jvm/java-17-openjdk-arm64/bin:$PATH
      - STREAMLIT_SERVER_HEADLESS=true
      - STREAMLIT_SERVER_RUN_ON_SAVE=true
    volumes:
      - ./notebooks:/app    
    working_dir: /app
    command: streamlit run app.py --server.port=8501 --server.address=0.0.0.0



volumes:
  hadoop_namenode:
  hadoop_datanode:
  mongodb_data:

networks:
  hadoop-net:
    driver: bridge
