{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6f7a0c-e3eb-499e-b6f7-dc8c73d01acf",
   "metadata": {},
   "source": [
    "# Ściąganie danych z reddita i zapis do HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72c3bc-035c-4145-b8b9-d77be43632ff",
   "metadata": {},
   "source": [
    "## 1. Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c67731ff-2ee5-4219-9a36-4aeb7fecbb98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:46:58.118072Z",
     "start_time": "2025-06-03T13:46:57.722196Z"
    }
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eaf708-2356-4f98-87ba-689d4732d647",
   "metadata": {},
   "source": [
    "## 2. Konfiguracja PRAW (Reddit API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c2f15a-d035-4fce-bb4c-c3ffc4bccd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:47:02.317935Z",
     "start_time": "2025-06-03T13:47:02.130167Z"
    }
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"YOUR_CLIENT_ID\",\n",
    "    client_secret=\"YOUR_CLIENT_SECRET\",\n",
    "    user_agent=\"YOUR_USER_AGENT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad8d66-0d52-4332-bd8d-06ddc463be9d",
   "metadata": {},
   "source": [
    "## 3. Funkcja pobierająca dane z Reddita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df317b4e-32e8-4af9-bc0d-998fbfd55e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:47:07.272752Z",
     "start_time": "2025-06-03T13:47:07.268290Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_reddit_posts(subreddit_name=\"movieReviews\", pages=3, limit_per_page=50):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    all_posts = []\n",
    "    seen_ids = set()\n",
    "\n",
    "    after = None\n",
    "    for page in range(pages):\n",
    "        posts = subreddit.new(limit=limit_per_page, params={\"after\": after})\n",
    "        for submission in posts:\n",
    "            if submission.id in seen_ids:\n",
    "                continue\n",
    "\n",
    "            submission.comments.replace_more(limit=0)\n",
    "            comments = [\n",
    "                comment.body\n",
    "                for comment in submission.comments.list()\n",
    "                if comment.author and comment.author.name != \"AutoModerator\"\n",
    "            ]\n",
    "\n",
    "            post = {\n",
    "                \"id\": submission.id,\n",
    "                \"title\": submission.title,\n",
    "                \"selftext\": submission.selftext,\n",
    "                \"created_utc\": datetime.utcfromtimestamp(submission.created_utc).isoformat(),\n",
    "                \"num_comments\": submission.num_comments,\n",
    "                \"score\": submission.score,\n",
    "                \"comments\": comments,\n",
    "                \"subreddit\": subreddit_name\n",
    "            }\n",
    "            all_posts.append(post)\n",
    "            seen_ids.add(submission.id)\n",
    "            after = submission.name\n",
    "        time.sleep(1)\n",
    "\n",
    "    return all_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e07bd7-8fa4-4aa4-8f75-093ca95abaea",
   "metadata": {},
   "source": [
    "## 4. Pobierz posty i zapisz do csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91cc203e-cc32-4bdb-907f-4c294a43ef67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:49:29.361967Z",
     "start_time": "2025-06-03T13:47:19.815419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane zapisane do reddit_data.json\n"
     ]
    }
   ],
   "source": [
    "posts = fetch_reddit_posts(pages=10, limit_per_page=50)\n",
    "with open(\"reddit_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(posts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Dane zapisane do reddit_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08abaa8d-92f7-4127-8a86-28fb67996696",
   "metadata": {},
   "source": [
    "## 5. Zapisz plik json do HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e64516b0-e63e-4965-aab6-26fcb4626191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T14:28:50.430419Z",
     "start_time": "2025-06-03T14:25:50.915780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- comments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- created_utc: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- num_comments: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- selftext: string (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#przekopiowac na dockera i z dockera na hdfs za pomoca hdfs put\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Copy JSON to HDFS\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000/\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.option(\"multiline\", \"true\").json(\"reddit_data.json\")\n",
    "df.printSchema()\n",
    "\n",
    "df.write.mode(\"overwrite\").json(\"hdfs://namenode:9000/data/reddit_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefbcf71-a78d-4374-9a9d-9ef71f63a312",
   "metadata": {},
   "source": [
    "## Pobieranie danych z reddita przez pushshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7f7634-53a6-42df-b678-323e21c84527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Błąd odpowiedzi: 403\n",
      "0 postów zapisanych do reddit_data_pushshift.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_reddit_posts_pushshift(subreddit=\"movieReviews\", start_year=2022, end_year=2023, max_posts=500):\n",
    "    all_posts = []\n",
    "    seen_ids = set()\n",
    "    size = 100\n",
    "    collected = 0\n",
    "    after = int(datetime(start_year, 1, 1).timestamp())\n",
    "    before = int(datetime(end_year + 1, 1, 1).timestamp())\n",
    "\n",
    "    while collected < max_posts:\n",
    "        url = \"https://api.pushshift.io/reddit/search/submission/\"\n",
    "        params = {\n",
    "            \"subreddit\": subreddit,\n",
    "            \"after\": after,\n",
    "            \"before\": before,\n",
    "            \"size\": size,\n",
    "            \"sort\": \"asc\",\n",
    "            \"sort_type\": \"created_utc\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(\"Błąd odpowiedzi:\", response.status_code)\n",
    "            break\n",
    "\n",
    "        data = response.json().get(\"data\", [])\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        for submission in data:\n",
    "            if submission[\"id\"] in seen_ids:\n",
    "                continue\n",
    "\n",
    "            post = {\n",
    "                \"id\": submission[\"id\"],\n",
    "                \"title\": submission.get(\"title\", \"\"),\n",
    "                \"selftext\": submission.get(\"selftext\", \"\"),\n",
    "                \"created_utc\": datetime.utcfromtimestamp(submission[\"created_utc\"]).isoformat(),\n",
    "                \"subreddit\": subreddit\n",
    "            }\n",
    "\n",
    "            all_posts.append(post)\n",
    "            seen_ids.add(submission[\"id\"])\n",
    "            collected += 1\n",
    "\n",
    "            if collected >= max_posts:\n",
    "                break\n",
    "\n",
    "        # Ustaw nowy znacznik czasu do kolejnej paginacji\n",
    "        after = data[-1][\"created_utc\"]\n",
    "        time.sleep(1)\n",
    "\n",
    "    with open(\"reddit_data_pushshift.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_posts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"{len(all_posts)} postów zapisanych do reddit_data_pushshift.json\")\n",
    "\n",
    "# Wywołanie\n",
    "fetch_reddit_posts_pushshift()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a6a81-5925-4131-8d7a-e85e90c3fb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
